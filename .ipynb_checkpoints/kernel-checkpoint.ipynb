{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f6a7a7360c27a2dd9388ae2db3cd0ba674dad884"
   },
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "fd467dcd4e77a0e101a9e901b9574c3c8b6994df"
   },
   "outputs": [],
   "source": [
    "# do this to make Pandas show all the columns of a DataFrame, otherwise it just shows a summary\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5a65a9db82e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../input/train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "train_id = df_train['Id']\n",
    "test_id = df_test['Id']\n",
    "\n",
    "train_idhogar = df_train['idhogar']\n",
    "test_idhogar = df_train['idhogar']\n",
    "\n",
    "df_train.drop(columns=['Id', 'idhogar'], inplace=True)\n",
    "df_test.drop(columns=['Id', 'idhogar'], inplace=True)\n",
    "\n",
    "print(\"Shape of train data: \", df_train.shape)\n",
    "print(\"Shape of test data: \", df_test.shape)\n",
    "\n",
    "ntrain = df_train.shape[0]\n",
    "ntest = df_test.shape[0]\n",
    "\n",
    "all_data = pd.concat((df_train, df_test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c8c4bfaba807b5fc2e5ee76044931d1793f0a181"
   },
   "outputs": [],
   "source": [
    "print(\"A glimpse at the columns of training data:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3b29a4d1b6aae29e9ebf1f70886a4bea6fe7fd6e"
   },
   "outputs": [],
   "source": [
    "print(\"The feature that we need to predict: \", set(df_train.columns) - set(df_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba18d69918ba25e9d467ebd92b3320333dbaab90"
   },
   "source": [
    "Let's see a description of `Target`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "828f63a748a23e6fc86ad95b1207ca655af6d66e"
   },
   "outputs": [],
   "source": [
    "df_train['Target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "faf42c1ad044db86af69cd2f9ff291346f427b18"
   },
   "outputs": [],
   "source": [
    "def barplot_with_anotate(feature_list, y_values, plotting_space=plt, annotate_vals=None):\n",
    "    x_pos = np.arange(len(feature_list))\n",
    "    plotting_space.bar(x_pos, y_values);\n",
    "    plotting_space.xticks(x_pos, feature_list, rotation=270);\n",
    "    if annotate_vals == None:\n",
    "        annotate_vals = y_values\n",
    "    for i in range(len(feature_list)):\n",
    "        plotting_space.text(x=x_pos[i]-0.3, y=y_values[i]+1.0, s=annotate_vals[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "025951fcece4164af2887bb8945804a8d4a83e6a"
   },
   "outputs": [],
   "source": [
    "poverty_label_sizes = list(df_train.groupby('Target').size())\n",
    "\n",
    "barplot_with_anotate(['extreme', 'moderate', 'vulnerable', 'non-vulnerable'], poverty_label_sizes,\n",
    "                     annotate_vals = [str(round((count/df_train.shape[0])*100, 2))+'%' \n",
    "                                      for count in poverty_label_sizes]);\n",
    "plt.rcParams[\"figure.figsize\"] = [6, 6];\n",
    "plt.xlabel('Poverty Label');\n",
    "plt.ylabel('No. of people');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e73c25bf31a57073488577073a4ba17e76aa50ee"
   },
   "source": [
    "So, we can conclude that **_a majority (67.74%) of the individuals fall within the `Non-vulnerable` category_**. This is follwed by `moderate`(16.71%) -> `vulnerable` (12.65%) -> `extreme` (7.9%).\n",
    "\n",
    "Now, let's try to understand what it means to live under such conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dwelling_property(property_df):\n",
    "    _, axarr = plt.subplots(nrows=2, ncols=2, sharex='col', sharey='row')\n",
    "\n",
    "    target_idx = 0\n",
    "    for row in range(2):\n",
    "        for col in range(2):\n",
    "            percentage_list = [round((count/poverty_label_sizes[target_idx])*100, 2)\n",
    "                                 for count in list(property_df.iloc[target_idx, :])]\n",
    "            x_pos = list(range(len(property_df.columns)))\n",
    "            \n",
    "            axarr[row, col].bar(x_pos, \n",
    "                                percentage_list, \n",
    "                                color='y')\n",
    "            \n",
    "            axarr[row, col].set_title('For individuals in Poverty group=' + str(target_idx+1))\n",
    "            \n",
    "            xtick_labels = list(property_df.columns)\n",
    "            xtick_labels.insert(0, '') # insert a blank coz `set_xticklabels()` skips the 1st element ##why??\n",
    "            axarr[row, col].set_xticklabels(xtick_labels, rotation=300)\n",
    "            \n",
    "            axarr[row, col].set_ylim(bottom=0, top=100)\n",
    "            #axarr[row, col].set_xlim(left=0, right=len(property_df.columns))\n",
    "            \n",
    "            for i in range(len(property_df.columns)):\n",
    "                axarr[row, col].annotate(xy=(x_pos[i]-0.3, percentage_list[i]+1.0), s=percentage_list[i]);\n",
    "            \n",
    "            axarr[0, 0].set_ylabel(\"Percentage of the total in this poverty group\");\n",
    "            axarr[1, 0].set_ylabel(\"Percentage of the total in this poverty group\");\n",
    "            axarr[1, 0].set_xlabel(\"Types of material\");\n",
    "            axarr[1, 1].set_xlabel(\"Types of material\");\n",
    "\n",
    "            axarr[row, col].autoscale(enable=True, axis='x')\n",
    "            target_idx+=1\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = [16, 16];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56a6d23fbb7b4dab12096307c0fe428d0bf95a2f"
   },
   "source": [
    "### Outside wall material of the house:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4d9f391556abac1bf6b5f3c3f02637b5266c0c4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outside_wall_material_df = df_train.groupby('Target').sum()[['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', \n",
    "                                  'paredzinc', 'paredfibras', 'paredother']]\n",
    "outside_wall_material_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "paredblolad, =1 if predominant material on the outside wall is block or brick\n",
    "paredzocalo, \"=1 if predominant material on the outside wall is socket (wood,  zinc or absbesto\"\n",
    "paredpreb, =1 if predominant material on the outside wall is prefabricated or cement\n",
    "pareddes, =1 if predominant material on the outside wall is waste material\n",
    "paredmad, =1 if predominant material on the outside wall is wood\n",
    "paredzinc, =1 if predominant material on the outside wall is zink\n",
    "paredfibras, =1 if predominant material on the outside wall is natural fibers\n",
    "paredother, =1 if predominant material on the outside wall is other\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_dwelling_property(outside_wall_material_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that a majority (69.26%) of the people living under poverty group 4 (non-vulnerable) have brick wall on the outside. As we go from there to group 1 (extreme), the percentage of people having brick wall decreases. Cement wall and wood walls become increasingly more common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floor material of the house:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_material_df = df_train.groupby('Target').sum()[['pisomoscer', 'pisocemento', 'pisoother',\n",
    "                                                      'pisonatur', 'pisonotiene', 'pisomadera']]\n",
    "floor_material_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pisomoscer, \"=1 if predominant material on the floor is mosaic,  ceramic,  terrazo\"\n",
    "pisocemento, =1 if predominant material on the floor is cement\n",
    "pisoother, =1 if predominant material on the floor is other\n",
    "pisonatur, =1 if predominant material on the floor is  natural material\n",
    "pisonotiene, =1 if no floor at the household\n",
    "pisomadera, =1 if predominant material on the floor is wood\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dwelling_property(floor_material_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toilet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toilet_df = df_train.groupby('Target').sum()[['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5',\n",
    "                                              'sanitario6']]\n",
    "toilet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "sanitario1, =1 no toilet in the dwelling\n",
    "sanitario2, =1 toilet connected to sewer or cesspool\n",
    "sanitario3, =1 toilet connected to  septic tank\n",
    "sanitario5, =1 toilet connected to black hole or letrine\n",
    "sanitario6, =1 toilet connected to other system\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_dwelling_property(toilet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rubbish disposal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubbish_disposal_df = df_train.groupby('Target').sum()[['elimbasu1', 'elimbasu2', 'elimbasu3',\n",
    "                                                        'elimbasu4', 'elimbasu5', 'elimbasu6']]\n",
    "rubbish_disposal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "elimbasu1, =1 if rubbish disposal mainly by tanker truck\n",
    "elimbasu2, =1 if rubbish disposal mainly by botan hollow or buried\n",
    "elimbasu3, =1 if rubbish disposal mainly by burning\n",
    "elimbasu4, =1 if rubbish disposal mainly by throwing in an unoccupied space\n",
    "elimbasu5, \"=1 if rubbish disposal mainly by throwing in river,  creek or sea\"\n",
    "elimbasu6, =1 if rubbish disposal mainly other\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dwelling_property(rubbish_disposal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roof material of the house:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roof_material_df = df_train.groupby('Target').sum()[['techozinc', 'techoentrepiso', 'techocane', 'techootro']]\n",
    "roof_material_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "techozinc, =1 if predominant material on the roof is metal foil or zink\n",
    "techoentrepiso, \"=1 if predominant material on the roof is fiber cement,  mezzanine \"\n",
    "techocane, =1 if predominant material on the roof is natural fibers\n",
    "techootro, =1 if predominant material on the roof is other\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dwelling_property(roof_material_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water provision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_provision_df = df_train.groupby('Target').sum()[['abastaguadentro', 'abastaguafuera', 'abastaguano']]\n",
    "water_provision_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "abastaguadentro, =1 if water provision inside the dwelling\n",
    "abastaguafuera, =1 if water provision outside the dwelling\n",
    "abastaguano, =1 if no water provision\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dwelling_property(water_provision_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electricity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df = df_train.groupby('Target').sum()[['public', 'planpri', 'noelec', 'coopele']]\n",
    "electricity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "public, \"=1 electricity from CNFL,  ICE,  ESPH/JASEC\"\n",
    "planpri, =1 electricity from private plant\n",
    "noelec, =1 no electricity in the dwelling\n",
    "coopele, =1 electricity from cooperative\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dwelling_property(electricity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main source of energy in cooking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooking_energy_df = df_train.groupby('Target').sum()[['energcocinar1', 'energcocinar2', 'energcocinar3',\n",
    "                                                      'energcocinar4']]\n",
    "cooking_energy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "energcocinar1, =1 no main source of energy used for cooking (no kitchen)\n",
    "energcocinar2, =1 main source of energy used for cooking electricity\n",
    "energcocinar3, =1 main source of energy used for cooking gas\n",
    "energcocinar4, =1 main source of energy used for cooking wood charcoal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dwelling_property(cooking_energy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "059177a19c444417ff140ed599278ade6f10fbaa"
   },
   "source": [
    "## Numerical or Categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a65dda00b8bff08d056e019c5326051c71ddc311"
   },
   "outputs": [],
   "source": [
    "num_features = all_data._get_numeric_data().columns\n",
    "num_features_length = len(num_features)\n",
    "\n",
    "categ_features = pd.Index(list(set(all_data.columns) - set(num_features)))\n",
    "categ_features_length = len(categ_features)\n",
    "\n",
    "print(\"Number of numerical features: \", num_features_length)\n",
    "print(\"Number of categorical features: \", categ_features_length)\n",
    "\n",
    "labels = ['numeric', 'categorical']\n",
    "colors = ['y', 'r']\n",
    "plt.pie([num_features_length, categ_features_length], \n",
    "        labels=labels, \n",
    "        autopct='%1.1f%%', \n",
    "        shadow=True, \n",
    "        colors=colors);\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 8];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03afcd29898ef2ec0fd1070636a14be2ab3d0745"
   },
   "source": [
    "Let's have a look at the 3 categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c3296f08725b261e6f18d6e111f5ed854aea3bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data[categ_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f292e9d64cd72c1290e0830791865eef99b7953"
   },
   "source": [
    "According to the [data description provided with the challenge](https://www.kaggle.com/c/costa-rican-household-poverty-prediction/data), the above 3 features should take numerical values but they contain lots of 'yes' and 'no' values as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9cdcf15232602ec69996a4ceb5682e8f64e6fecf"
   },
   "outputs": [],
   "source": [
    "_, axarr = plt.subplots(nrows=1, ncols=3, sharey='row')\n",
    "\n",
    "for idx, feature in enumerate(categ_features):\n",
    "    sns.countplot(x=feature, data=all_data[all_data[feature].isin(['yes', 'no'])], ax=axarr[idx])\n",
    "    \n",
    "plt.rcParams[\"figure.figsize\"] = [12, 6];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e3df006043c9433e9141003fbf5add72d38fc9c8"
   },
   "source": [
    "A look at [this discussion](https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#359554) showed that there is a glitch with `dependency`, `edjefe` and `edjefa`. In all of these cases,, 'yes' implies 1 and 'no' implies 0. So, let's fix that.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c34a5b84f962849c26289db10034fc3c48401b6"
   },
   "outputs": [],
   "source": [
    "yes_no_map = {'no': 0, 'yes': 1}\n",
    "    \n",
    "all_data['dependency'] = all_data['dependency'].replace(yes_no_map).astype(np.float32)\n",
    "all_data['edjefe'] = all_data['edjefe'].replace(yes_no_map).astype(np.float32)\n",
    "all_data['edjefa'] = all_data['edjefa'].replace(yes_no_map).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "17691af4750d19095cadceadb3c4ba372eadabe8",
    "collapsed": true
   },
   "source": [
    "Now, all the features are numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14b6b12908ba730523b59a4f85cfad25de93829d"
   },
   "source": [
    "### Numerical features that are binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9766f2e780bb1095b34e42a90b7838387bd02d7c"
   },
   "outputs": [],
   "source": [
    "num_binary_features = []\n",
    "\n",
    "for feature in df_train.columns:\n",
    "    if sorted(df_train[feature].unique()) in [[0, 1], [0], [1]]:\n",
    "        num_binary_features.append(feature)\n",
    "        \n",
    "print(\"Total number of binary-numerical features: \", len(num_binary_features))\n",
    "print(\"Binary-numerical features: \")\n",
    "num_binary_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d946a74b8de7b35e598ca170de9d3f4b11b9606"
   },
   "source": [
    "### Non-binary features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4e1e18963115cc0f47001ba8beb2dfbf0b344e04"
   },
   "outputs": [],
   "source": [
    "num_non_binary_features = [feature for feature in df_train.columns if feature not in num_binary_features]\n",
    "\n",
    "print(\"Total number of non-binary-numerical features: \", len(num_non_binary_features))\n",
    "print(\"Non-binary numerical features: \")\n",
    "\n",
    "num_non_binary_features_dict = {feature: len(df_train[feature].unique()) for feature in num_non_binary_features}\n",
    "\n",
    "num_non_binary_features_sorted = sorted(num_non_binary_features_dict, \n",
    "                                        key=lambda feature: num_non_binary_features_dict[feature], \n",
    "                                        reverse=True)\n",
    "\n",
    "num_non_binary_features_len_sorted = [num_non_binary_features_dict[feature] for feature in num_non_binary_features_sorted]\n",
    "\n",
    "barplot_with_anotate(num_non_binary_features_sorted, num_non_binary_features_len_sorted);\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 16];\n",
    "plt.ylabel(\"No. of unique values\");\n",
    "plt.xlabel(\"Non-binary numerical features\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e37182603dd748ea97a2d1f26271ef10163f766e",
    "collapsed": true
   },
   "source": [
    "Out of these 39 features, the following are continuous in nature:\n",
    "* v2al\n",
    "* meaneduc\n",
    "* SQBmeaned\n",
    "* dependency\n",
    "* SQBdependency\n",
    "\n",
    "\n",
    "All the other features are discrete in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ddee68b13aa29aabb5bd46b6704544538b99bbb"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f1130a8f8168fe324eed1a219309de1f7963b40"
   },
   "source": [
    "### Binary features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "60fbb50703da0d933571bc6234d7fad2446c0bcb"
   },
   "outputs": [],
   "source": [
    "all_data[num_binary_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a5a1d1189cff167c9c7fc11128fec0cf6055883"
   },
   "source": [
    "### Non-binary continuous features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d9c578cb589d35e234240a05a701c9bb04bea9b5"
   },
   "outputs": [],
   "source": [
    "num_conti_features = pd.Index(['v2a1', 'meaneduc', 'dependency', 'SQBmeaned', 'SQBdependency'])\n",
    "all_data[num_conti_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5bcda7ba9759008c087386d1e358e0bb5e53ebaa"
   },
   "source": [
    "### Non-binary discrete features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "999982752da4ce330ce19abf5a5daf60250c9a3c"
   },
   "outputs": [],
   "source": [
    "num_discrete_features = pd.Index([feature for feature in num_non_binary_features if feature not in num_conti_features])\n",
    "all_data[num_discrete_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8834e64c4cc860cf014d5bc35b4171193b28a8af"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14ffd3fb2af8e12892f201717fc3a66ddf807feb"
   },
   "source": [
    "## Missing values imputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5e4f2921552231adc06321c9fd90ddef9b87dfca"
   },
   "outputs": [],
   "source": [
    "def missing_features(data, column_set):\n",
    "    incomplete_features = {feature: data.shape[0]-sum(data[feature].value_counts())\n",
    "                                   for feature in column_set\n",
    "                                   if not sum(data[feature].value_counts()) == data.shape[0]}\n",
    "    incomplete_features_sorted = sorted(incomplete_features, key=lambda feature: incomplete_features[feature], reverse=True)\n",
    "    incompleteness = [round((incomplete_features[feature]/data.shape[0])*100, 2) for feature in incomplete_features_sorted]\n",
    "    barplot_with_anotate(incomplete_features_sorted, incompleteness)\n",
    "    plt.ylabel(\"Percentage (%) of values that are missing\")\n",
    "    plt.rcParams[\"figure.figsize\"] = [12, 6]\n",
    "    \n",
    "    for feature, percentage in zip(incomplete_features_sorted, incompleteness):\n",
    "        print(\"Feature:\", feature)\n",
    "        print(\"No. of NaNs:\", incomplete_features[feature], \"(\", percentage, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6f1700a0d8ec1eb5bc12390c4be35566c4d2296"
   },
   "outputs": [],
   "source": [
    "missing_features(all_data, all_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d525792bd8b4ea9018bdae334112f02ca9493b6f"
   },
   "source": [
    "* [This discussion](https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#360609) shows how missing values of `v2a1` and `v18q1` should be handled.\n",
    "\n",
    "* `rez_esc` (Years behind in school): NaN implies that the person does not remember. Considering that along with the large percentage of NaN values, we are better off dropping that column.\n",
    "\n",
    "\n",
    "* `meaneduc` and `SQBmeaned`: With the average of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce30fff8cb083912b0bd9db119d923bb2efb7629"
   },
   "source": [
    "### `v2a1` :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2eaacbccff859d04d0e9e9b301ebf2d8bea2c00"
   },
   "outputs": [],
   "source": [
    "# entries which have both v2a1 as NaN and tipovivi3 as 0\n",
    "all_data[['v2a1', 'tipovivi3']][all_data['tipovivi3'] == 0][all_data['v2a1'].isnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a2222819b62fc83d079a11c7fba961dabe24373"
   },
   "source": [
    "We see that all those entries where `v2a1` is Nan also have `tipovivi3` as 0, which implies that all those houses are not rented. \n",
    "\n",
    "Hence, we should fill the missing values of `v2a1` with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31e0be80393675cb2ab95f30bda03e3c75ba9dbc"
   },
   "outputs": [],
   "source": [
    "# handling v2a1\n",
    "all_data.loc[:, 'v2a1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b632dff71c5fe76085debd937fe7fb9da234db97"
   },
   "source": [
    "### `v18q1` :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85d1587f852fb5af759d3c28874b17f58f62a55c"
   },
   "outputs": [],
   "source": [
    "# entries which have v18q as 0 and v18q1 as NaN\n",
    "all_data[['v18q1', 'v18q']][all_data['v18q'] == 0][all_data['v18q1'].isnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5eebad117dc9d03e917bc45ebe61bf1477d3e619"
   },
   "source": [
    "We see that `v18q1` is `NaN` only for those entries which have `v18q` == 0. Thus, `v18q1` is missing only when the house does not have a tablet. \n",
    "\n",
    "Hence, we should fill the missing values of `v18q1` with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d155bd1b82a11e32e1e814dbce88015de4e166f2"
   },
   "outputs": [],
   "source": [
    "# handling v18q1\n",
    "all_data.loc[:, 'v18q1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fc6a768e76ee8f44cc61a8fb0d4164029e8d9b9f"
   },
   "source": [
    "### `meaneduc` and `SQBmeaned` :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da35f656c6535edf90c4b973a9095de5869be4e4"
   },
   "outputs": [],
   "source": [
    "# handling meaneduc and SQBmeaned\n",
    "all_data.loc[:, 'meaneduc'].fillna(all_data['meaneduc'].mean(), inplace=True)\n",
    "all_data.loc[:, 'SQBmeaned'].fillna(all_data['SQBmeaned'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77035587ec19775ccd0eafe4fc97b5b3583a97ab"
   },
   "source": [
    "### `rez_esc` :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40d2bc0f5f6549e16ac7820da076ee1f15f7f268"
   },
   "source": [
    "Drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "828175116c26cbf98fc44d5c101fb4adc359a622"
   },
   "outputs": [],
   "source": [
    "all_data.drop(columns=['rez_esc'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to ordinal\n",
    "\n",
    "These features have order in their meaning:\n",
    "```\n",
    "epared1, =1 if walls are bad\n",
    "epared2, =1 if walls are regular\n",
    "epared3, =1 if walls are good\n",
    "etecho1, =1 if roof are bad\n",
    "etecho2, =1 if roof are regular\n",
    "etecho3, =1 if roof are good\n",
    "eviv1, =1 if floor are bad\n",
    "eviv2, =1 if floor are regular\n",
    "eviv3, =1 if floor are good\n",
    "instlevel1, =1 no level of education\n",
    "instlevel2, =1 incomplete primary\n",
    "instlevel3, =1 complete primary\n",
    "instlevel4, =1 incomplete academic secondary level\n",
    "instlevel5, =1 complete academic secondary level\n",
    "instlevel6, =1 incomplete technical secondary level\n",
    "instlevel7, =1 complete technical secondary level\n",
    "instlevel8, =1 undergraduate and higher education\n",
    "instlevel9, =1 postgraduate higher education\n",
    "```\n",
    "We should use them as ordinal features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''all_data['WallQual'] = all_data['epared1'] + 2*all_data['epared2'] + 3*all_data['epared3']\n",
    "\n",
    "all_data['RoofQual'] = all_data['etecho1'] + 2*all_data['etecho2'] + 3*all_data['etecho3']\n",
    "\n",
    "all_data['FloorQual'] = all_data['eviv1'] + 2*all_data['eviv2'] + 3*all_data['eviv3']'''\n",
    "\n",
    "all_data['EducationLevel'] = all_data['instlevel1'] + 2*all_data['instlevel2'] + 3*all_data['instlevel3'] + \\\n",
    "    4*all_data['instlevel4'] + 5*all_data['instlevel5'] + 6*all_data['instlevel6'] + 7*all_data['instlevel7'] + \\\n",
    "    8*all_data['instlevel8'] + 9*all_data['instlevel9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop(columns=['epared1', 'epared2', 'epared3',\n",
    "                       'etecho1', 'etecho2', 'etecho3',\n",
    "                       'eviv1', 'eviv2', 'eviv3',\n",
    "                       'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5',\n",
    "                       'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54cdd638744c30d3bdff618815da1e495a923cb5"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "91068ec0777df4b9117dd5f079db9f7441bae135"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2196eea82a7403d1ed0cb6160b28bde2a4dc72ca"
   },
   "outputs": [],
   "source": [
    "nvalidate = int(0.2 * ntrain)\n",
    "ntrain = int(ntrain - nvalidate)\n",
    "\n",
    "df_train = all_data[:ntrain][:]\n",
    "df_validate = all_data[ntrain:ntrain+nvalidate][:]\n",
    "df_test = all_data[ntrain+nvalidate:][:]\n",
    "df_test = df_test.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "67ac68193120c187a1f30af800179be6b09a5ae2"
   },
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_validate.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "9966e87f67ca16f6c3f43b8e10300e4069b115d5"
   },
   "outputs": [],
   "source": [
    "X_train= df_train.drop('Target', axis= 1)\n",
    "Y_train= df_train['Target']\n",
    "\n",
    "X_validate = df_validate.drop('Target', axis=1)\n",
    "Y_validate = df_validate['Target']\n",
    "\n",
    "X_test= df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "01d819bc7da59844a62699e525b46c4f1ba4acc4"
   },
   "outputs": [],
   "source": [
    "def get_validation_score(model):\n",
    "    Y_validate_pred = model.predict(X_validate)\n",
    "    return f1_score(Y_validate, Y_validate_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a175bbff884bda09551276863ff18248b8b4fd78"
   },
   "outputs": [],
   "source": [
    "validation_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1653aea0f6e97216709ec68f482f709261e005fe"
   },
   "source": [
    "### Gaussian Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "d77d2b081986f41b7712b7701b6da0d25166fb44"
   },
   "outputs": [],
   "source": [
    "naive_bayes_classifier = GaussianNB()\n",
    "naive_bayes_classifier.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a86e84ae26837973a0620315d4f2bc1ee2e3c9b4"
   },
   "outputs": [],
   "source": [
    "validation_scores['Naive Bayes'] = get_validation_score(naive_bayes_classifier)\n",
    "print(validation_scores['Naive Bayes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aca44208ae24a72f06f5ed79e8ab2072c2ab6ca7"
   },
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "62fe02fb875304909ef856c3ae033288df1ffc37"
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "22da9a6e7676c4a013d502eb1187f697a9e3b48b"
   },
   "outputs": [],
   "source": [
    "validation_scores['Random Forest'] = get_validation_score(random_forest)\n",
    "print(validation_scores['Random Forest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5869bf608faecd3b3e097840c6908422bec3319a"
   },
   "source": [
    "### SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7c5b56af92c8183158fcde602e25beaa453896ae"
   },
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9784d0023b94b55169baecd22437755dc0e22706"
   },
   "outputs": [],
   "source": [
    "validation_scores['SVC'] = get_validation_score(svc)\n",
    "print(validation_scores['SVC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6688a472925627e0e1483c1d1a5c75dc6ddb5f94"
   },
   "source": [
    "### LightGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7de7c3f36bec26cb65ce52d33393271c59107c82"
   },
   "outputs": [],
   "source": [
    "lightgbm = lgb.LGBMClassifier()\n",
    "lightgbm.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7613bb2a67780b075cddaefd24143b613dd87e57"
   },
   "outputs": [],
   "source": [
    "validation_scores['LightGBM'] = get_validation_score(lightgbm)\n",
    "print(validation_scores['LightGBM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59737cd8386c2fca497134c73e9f11c2184054bf"
   },
   "source": [
    "### XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7d4a84ef11ce527111c40312d109b80ffc61628"
   },
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier()\n",
    "xgboost.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c905adec507cf7c3c9eb918623012be094a3918"
   },
   "outputs": [],
   "source": [
    "validation_scores['XGBoost'] = get_validation_score(xgboost)\n",
    "print(validation_scores['XGBoost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44f081b091b7720bdb8b12e4fae8425a70030835"
   },
   "source": [
    "## Comparing the various scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "224fbf8e14ac2cabb35cf8004588c12aea38c227"
   },
   "outputs": [],
   "source": [
    "models_with_scores = pd.DataFrame({\n",
    "    'Model': list(validation_scores.keys()),\n",
    "    'Validation Score': list(validation_scores.values())})\n",
    "\n",
    "models_with_scores.sort_values(by='Validation Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "38fd56038e1d9d40d0b0500ba6eadc006539c283"
   },
   "source": [
    "## Submission Model: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "130a06800cd7ff41744dae6ea50588b9db702d90"
   },
   "outputs": [],
   "source": [
    "final_train = all_data[:ntrain+nvalidate][:]\n",
    "final_test = all_data[ntrain+nvalidate:][:]\n",
    "\n",
    "final_train_X = final_train.drop('Target', axis= 1)\n",
    "final_train_Y = final_train['Target']\n",
    "final_test_X = final_test.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8df9f8d24b710b9d6761e9727405bc755ee550d8"
   },
   "outputs": [],
   "source": [
    "submission_model = lgb.LGBMClassifier()\n",
    "submission_model.fit(final_train_X, final_train_Y);\n",
    "final_pred = submission_model.predict(final_test_X)\n",
    "final_pred = final_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06e6ef474b9f26cef6c95186cd58152468b2a99a"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': test_id,\n",
    "                           'Target': final_pred})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
